{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahmanziaur/DTClassifierTest/blob/main/R_20_09_22_one-hot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGQ6ycAF_EQ8",
        "outputId": "a5c727be-9f8d-407c-c99c-166be9c868f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate logistic regression on the breast cancer dataset with an one-hot encoding\n",
        "import timeit\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "# define the location of the dataset\n",
        "#from numpy import argmax as ag\n",
        "# url = \"https://raw.githubusercontent.com/rahmanziaur/DTClassifierTest/main/diabetic_data - Copy.csv\"\n",
        "\n",
        "# Rubel \n",
        "# url = \"/content/drive/MyDrive/0_ColabDatasets/final Medical.csv\"\n",
        "\n",
        "\n",
        "# load the dataset\n",
        "#dataset = pd.read_csv(url, header=None)\n",
        "# retrieve the array of data\n",
        "\n",
        "# Preprocessed Numeric Data\n",
        "# dataset=pd.read_csv('/content/drive/MyDrive/0_ColabDatasets/Processed3_TestDiabData_excepDiag.csv')\n",
        "\n",
        "# Original raw Data\n",
        "dataset=pd.read_csv('https://raw.githubusercontent.com/rahmanziaur/DTClassifierTest/main/diabetic_data_exceptDiag.csv')\n",
        "\n",
        "# dropping 'gender' because object to int type change issue\n",
        "# not required if not using exported .csv dataset \n",
        "\n",
        "# del dataset[dataset.columns[0]]\n",
        "\n",
        "# moving the target column at the end. No need for Rubel\n",
        "column_to_move = dataset.pop('readmitted')\n",
        "dataset.insert(len(dataset.columns), 'readmitted', column_to_move)\n",
        "\n",
        "\n",
        "\n",
        "data = dataset.values\n",
        "# separate into input and output columns\n",
        "X = data[:, :-1].astype(str)\n",
        "y = data[:, -1].astype(str)\n",
        "# split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# one-hot encode input variables\n",
        "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "onehot_encoder.fit(X_train)\n",
        "X_train = onehot_encoder.transform(X_train)\n",
        "X_test = onehot_encoder.transform(X_test)\n",
        "# ordinal encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "y_train = label_encoder.transform(y_train)\n",
        "label_encoder.fit(y_test)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "# define the model\n",
        "clf = RandomForestClassifier()\n",
        "# fit on the training set\n",
        "clf.fit(X_train, y_train)\n",
        "# predict on test set\n",
        "yhat = clf.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.2f' % (accuracy*100),'%')"
      ],
      "metadata": {
        "id": "wCxOmmxukL_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c4c1af-9529-4be8-ed71-2fce62a1899b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 58.13 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of chi squared feature selection for categorical data\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "\t# load the dataset as a pandas DataFrame\n",
        "\tdata = read_csv(filename, header=None)\n",
        "\t# retrieve numpy array\n",
        "\tdataset = data.values\n",
        "\t# split into input (X) and output (y) variables\n",
        "\tX = dataset[:, :-1]\n",
        "\ty = dataset[:,-1]\n",
        "\t# format all fields as string\n",
        "\tX = X.astype(str)\n",
        "\treturn X, y\n",
        "\n",
        "# prepare input data\n",
        "def prepare_inputs(X_train, X_test):\n",
        "  oe = OrdinalEncoder()\n",
        "  oe.fit(X_train)\n",
        "  X_train_enc = oe.transform(X_train)\n",
        "  oe.fit(X_test)\n",
        "  X_test_enc = oe.transform(X_test)\n",
        "  return X_train_enc, X_test_enc\n",
        "\n",
        "# prepare target\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tle = LabelEncoder()\n",
        "\tle.fit(y_train)\n",
        "\ty_train_enc = le.transform(y_train)\n",
        "\ty_test_enc = le.transform(y_test)\n",
        "\treturn y_train_enc, y_test_enc\n",
        "\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "\tfs = SelectKBest(score_func=chi2, k='all')\n",
        "\tfs.fit(X_train, y_train)\n",
        "\tX_train_fs = fs.transform(X_train)\n",
        "\tX_test_fs = fs.transform(X_test)\n",
        "\treturn X_train_fs, X_test_fs, fs\n",
        "\n",
        "# load the dataset\n",
        "X, y = load_dataset('/content/drive/MyDrive/0_ColabDatasets/final Medical.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# prepare input data\n",
        "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
        "# prepare output data\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
        "# what are scores for the features\n",
        "for i in range(len(fs.scores_)):\n",
        "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
        "# plot the scores\n",
        "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "-l15EuUk77Xz",
        "outputId": "a58e08a4-8053-4fae-dbc8-e574196651cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0muniques\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b30c1eb19621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mX_train_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# prepare output data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0my_train_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m# feature selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mX_train_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_fs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b30c1eb19621>\u001b[0m in \u001b[0;36mprepare_targets\u001b[0;34m(y_train, y_test)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0my_train_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0my_test_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unique_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# numerical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_inverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         raise TypeError(\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;34m\"Encoders require their input to be uniformly \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;34mf\"strings or numbers. Got {types}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['int', 'str']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of a model fit using chi squared input features\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "\t# load the dataset as a pandas DataFrame\n",
        "\tdata = read_csv(filename, header=None)\n",
        "\t# retrieve numpy array\n",
        "\tdataset = data.values\n",
        "\t# split into input (X) and output (y) variables\n",
        "\tX = dataset[:, :-1]\n",
        "\ty = dataset[:,-1]\n",
        "\t# format all fields as string\n",
        "\tX = X.astype(str)\n",
        "\treturn X, y\n",
        "\n",
        "# prepare input data\n",
        "def prepare_inputs(X_train, X_test):\n",
        "  oe = OrdinalEncoder()\n",
        "  oe.fit(X_train)\n",
        "  X_train_enc = oe.transform(X_train)\n",
        "  oe.fit(X_test)\n",
        "  X_test_enc = oe.transform(X_test)\n",
        "  return X_train_enc, X_test_enc\n",
        "\n",
        "# prepare target\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tle = LabelEncoder()\n",
        "\tle.fit(y_train)\n",
        "\ty_train_enc = le.transform(y_train)\n",
        "\ty_test_enc = le.transform(y_test)\n",
        "\treturn y_train_enc, y_test_enc\n",
        "\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "\tfs = SelectKBest(score_func=chi2, k=30)\n",
        "\tfs.fit(X_train, y_train)\n",
        "\tX_train_fs = fs.transform(X_train)\n",
        "\tX_test_fs = fs.transform(X_test)\n",
        "\treturn X_train_fs, X_test_fs\n",
        "\n",
        "# load the dataset\n",
        "X, y = load_dataset('/content/drive/MyDrive/Colab Notebooks/Zia Sir/20-09-22/diabetic_data - Copy.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# prepare input data\n",
        "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
        "# prepare output data\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
        "# fit the model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train_fs, y_train_enc)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test_fs)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test_enc, yhat)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "SiMMDrO9_cpO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd2c5c4-c0c9-480b-e3fc-a02fe52d7694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 56.97\n"
          ]
        }
      ]
    }
  ]
}